{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405066ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d188619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_list, output_dir=\"./statistics\", verbose=True, warning=True):\n",
    "    \"\"\"\n",
    "    Reads LogPhase600 Excel files, computes AUC, maximal growth rate, maximal per-capita growth rate,\n",
    "    lag time statistics and writes them to files -- one for each condition.\n",
    "    \n",
    "    Certain assumptions are made for the data -- the most important ones\n",
    "    is that the number of wells per plate is 96 and that the sheets of the Excel file are named\n",
    "    consistently.\n",
    "    \n",
    "    Parameter file_list: an array containing the paths to the Excel files.\n",
    "    \"\"\"\n",
    "    \n",
    "    !mkdir -p output_dir\n",
    "\n",
    "    all_plate_numbers = []\n",
    "    ref_wells = None\n",
    "    ref_meta = None\n",
    "    ref_strains = None\n",
    "    ref_time = None\n",
    "\n",
    "    def original_datetime_converter(x):\n",
    "        t = str(x)\n",
    "        if len(t) != 8:\n",
    "            split_date = t.split(\" \")\n",
    "            day_mul = int(split_date[0].split(\"-\")[-1])\n",
    "            new_t = split_date[-1].split(\":\")\n",
    "            new_t[0] = str(int(new_t[0]) + 24*day_mul)\n",
    "            t = \":\".join(new_t)\n",
    "            if verbose: print(\"Replaced imported date\", str(x), \"with\", t)\n",
    "        return t\n",
    "\n",
    "    if verbose: \n",
    "        print(\"Starting data import...\")\n",
    "        print(\"File list:\")\n",
    "        for f in file_list:\n",
    "            print(f)\n",
    "        print()\n",
    "\n",
    "    for f in file_list:\n",
    "        if verbose: print(\"Processing:\", f)\n",
    "        for pn in range(1, int(len(pd.ExcelFile(f).sheet_names)/3) + 1):\n",
    "            if verbose: print(\"Plate\", pn)\n",
    "            plate_meta = pd.read_excel(f, sheet_name=\"Plate \" + str(pn) + \" - Results\", header=1)\n",
    "            plate_meta.iloc[:, 4] = plate_meta.iloc[:, 4].fillna(\"\")\n",
    "            plate_raw = pd.read_excel(f, sheet_name=\"Plate \" + str(pn) + \" - Raw Data\", header=1, converters={\"Time\": original_datetime_converter})\n",
    "            # plate_raw = plate_raw[[\"Time\"] + list(plate_meta[\"Well\"].values)]\n",
    "\n",
    "            tn = np.array([np.round(int(x.split(\":\")[0]) + (int(x.split(\":\")[1])/60), 2) for x in plate_raw[\"Time\"]])\n",
    "\n",
    "            if ref_time is None:\n",
    "                if verbose: print(\"Using\", f, \"time values as reference\")\n",
    "                ref_time = tn\n",
    "\n",
    "            if ref_meta is None:\n",
    "                if verbose: print(\"Using\", f, \"metadata columns as reference\")\n",
    "                ref_meta = plate_meta.columns.values\n",
    "\n",
    "            if ref_wells is None:\n",
    "                if verbose: print(\"Using\", f, \"raw data well names as reference\")\n",
    "                ref_wells = plate_raw.columns.values\n",
    "\n",
    "            # Assertions\n",
    "            if not np.all(ref_meta == plate_meta.columns.values) and warning:\n",
    "                print(\"--------------------------------------------\")\n",
    "                print(\"Warning: in file\", f, \"plate\", str(pn), \"metadata columns do not match to the reference.\")\n",
    "                mismatch_idx = np.where(ref_meta != plate_meta.columns.values)[0]\n",
    "                for mm in mismatch_idx:\n",
    "                    print(\"    Column\", plate_meta.columns.values[mm], \"!= reference\", ref_meta[mm])\n",
    "                print(\"--------------------------------------------\")\n",
    "\n",
    "            if not np.all(ref_wells == plate_raw.columns.values) and warning:\n",
    "                print(\"--------------------------------------------\")\n",
    "                print(\"Warning: in file\", f, \"plate\", str(pn), \"raw data columns do not match to the reference.\")\n",
    "                mismatch_idx = np.where(ref_wells != plate_raw.columns.values)[0]\n",
    "                for mm in mismatch_idx:\n",
    "                    print(\"    Column\", plate_raw.columns.values[mm], \"!= reference\", ref_wells[mm])\n",
    "                print(\"--------------------------------------------\")\n",
    "\n",
    "            if not np.all(ref_time == tn) and warning:\n",
    "                print(\"--------------------------------------------\")\n",
    "                print(\"Warning: in file\", f, \"plate\", str(pn), \"time vector does not match to the reference.\")\n",
    "                print(\"--------------------------------------------\")\n",
    "                # assert 0\n",
    "\n",
    "            assert np.all(np.array([len(str(x)) for x in plate_raw.Time]) == 8)\n",
    "            assert np.all(plate_meta.iloc[:, 3] + \" \" + plate_meta.iloc[:, 4] == plate_meta.iloc[0, 3] + \" \" + plate_meta.iloc[0, 4])\n",
    "            assert plate_meta.shape[0] == 96\n",
    "\n",
    "            plate_meta = plate_meta.set_index(\"Well\").loc[ref_wells[1:]].reset_index()\n",
    "            \n",
    "            \n",
    "            plate_t = np.array([np.round(int(x.split(\":\")[0]) + (int(x.split(\":\")[1])/60), 2) for x in plate_raw.to_numpy().T[0, :]])\n",
    "            plate_raw = plate_raw.to_numpy().T[1:, :]\n",
    "            plate_meta = plate_meta.to_numpy()\n",
    "            \n",
    "            data = pd.DataFrame(columns=[\"Well\", \"Short strain ID\", \"Long strain ID\", \"Stressor\", \"Concentration\", \"AUC\", \"Maximal growth rate\", \"Maximal per-capita growth rate\", \"Lag time (hours)\"])\n",
    "            data[\"Well\"] = plate_meta[:, 0].reshape(-1)\n",
    "            data[\"Short strain ID\"] = plate_meta[:, 1].reshape(-1)\n",
    "            data[\"Long strain ID\"] = plate_meta[:, 2].reshape(-1)\n",
    "            data[\"Stressor\"] = plate_meta[:, 3].reshape(-1)\n",
    "            data[\"Concentration\"] = plate_meta[:, 4].reshape(-1)\n",
    "\n",
    "            m = plate_raw.astype(float)\n",
    "            aucs = np.sum(m, axis=1)\n",
    "            gr = m.copy()\n",
    "            rho = m.copy()\n",
    "            for i in range(m.shape[0]):\n",
    "                gr[i, :] = np.array([0] + [(gr[i, j] - gr[i, j-1]) for j in range(1, m.shape[1])])\n",
    "                rho[i, :] = np.array([0] + [(rho[i, j] - rho[i, j-1])/rho[i, j-1] if rho[i, j-1] != 0 else 0 for j in range(1, m.shape[1])])\n",
    "\n",
    "            data[\"AUC\"] = aucs\n",
    "            data[\"Maximal growth rate\"] = np.max(gr, axis=1)\n",
    "            data[\"Maximal per-capita growth rate\"] = np.max(rho, axis=1)\n",
    "            data[\"Lag time (hours)\"] = [plate_t[np.where(gr[i] == np.max(gr[i]))[0][0]] for i in range(len(gr))]\n",
    "            \n",
    "            data.to_csv(output_dir + \"/\" + data[\"Stressor\"][0].replace(\" \", \"\") + \"_\" + data[\"Concentration\"][0].replace(\"/\", \"\").replace(\" \", \"\") + \".tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "        if verbose: print()\n",
    "\n",
    "    if verbose: print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1312a",
   "metadata": {},
   "source": [
    "# File processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf7014",
   "metadata": {},
   "source": [
    "### File list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5757a685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/set_5_R6/R6_CuSO4_1mM_1-2_H2O2_0,5mM_1-2_11-loka-2023 14-49-09.xlsx',\n",
       " './data/set_5_R6/R6_Cipro_1300ug(ml)_1-2_11-loka-2023 14-49-04.xlsx',\n",
       " './data/set_5_R6/R6_Azithro_25ug(ml)_1-2_Trimet_4000ug(ml)_1-2_11-loka-2023 14-48-52.xlsx',\n",
       " './data/set_5_R6/R6_Amxclv_25ug(ml)_1-2_NaCl_120mg(ml)_1-2_11-loka-2023 14-49-25.xlsx',\n",
       " './data/set_5_R6/R6_Control_1-2_Ceftrx_1300ug(ml)_1-2_11-loka-2023 14-49-16.xlsx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"./data/set_5_R6/*\")  # Directory where the LogPhase Excel files are\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ff217",
   "metadata": {},
   "source": [
    "### Reading files and writing statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0274f132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data import...\n",
      "File list:\n",
      "./data/set_5_R6/R6_CuSO4_1mM_1-2_H2O2_0,5mM_1-2_11-loka-2023 14-49-09.xlsx\n",
      "./data/set_5_R6/R6_Cipro_1300ug(ml)_1-2_11-loka-2023 14-49-04.xlsx\n",
      "./data/set_5_R6/R6_Azithro_25ug(ml)_1-2_Trimet_4000ug(ml)_1-2_11-loka-2023 14-48-52.xlsx\n",
      "./data/set_5_R6/R6_Amxclv_25ug(ml)_1-2_NaCl_120mg(ml)_1-2_11-loka-2023 14-49-25.xlsx\n",
      "./data/set_5_R6/R6_Control_1-2_Ceftrx_1300ug(ml)_1-2_11-loka-2023 14-49-16.xlsx\n",
      "\n",
      "Processing: ./data/set_5_R6/R6_CuSO4_1mM_1-2_H2O2_0,5mM_1-2_11-loka-2023 14-49-09.xlsx\n",
      "Plate 1\n",
      "Replaced imported date 1900-01-01 00:00:02 with 24:00:02\n",
      "Using ./data/set_5_R6/R6_CuSO4_1mM_1-2_H2O2_0,5mM_1-2_11-loka-2023 14-49-09.xlsx time values as reference\n",
      "Using ./data/set_5_R6/R6_CuSO4_1mM_1-2_H2O2_0,5mM_1-2_11-loka-2023 14-49-09.xlsx metadata columns as reference\n",
      "Using ./data/set_5_R6/R6_CuSO4_1mM_1-2_H2O2_0,5mM_1-2_11-loka-2023 14-49-09.xlsx raw data well names as reference\n",
      "Plate 2\n",
      "Replaced imported date 1900-01-01 00:00:02 with 24:00:02\n",
      "Plate 3\n",
      "Replaced imported date 1900-01-01 00:00:03 with 24:00:03\n",
      "Plate 4\n",
      "Replaced imported date 1900-01-01 00:00:03 with 24:00:03\n",
      "\n",
      "Processing: ./data/set_5_R6/R6_Cipro_1300ug(ml)_1-2_11-loka-2023 14-49-04.xlsx\n",
      "Plate 1\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "Plate 2\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "\n",
      "Processing: ./data/set_5_R6/R6_Azithro_25ug(ml)_1-2_Trimet_4000ug(ml)_1-2_11-loka-2023 14-48-52.xlsx\n",
      "Plate 1\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "Plate 2\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "Plate 3\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "Plate 4\n",
      "Replaced imported date 1900-01-01 00:00:02 with 24:00:02\n",
      "\n",
      "Processing: ./data/set_5_R6/R6_Amxclv_25ug(ml)_1-2_NaCl_120mg(ml)_1-2_11-loka-2023 14-49-25.xlsx\n",
      "Plate 1\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "Plate 2\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "Plate 3\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "Plate 4\n",
      "Replaced imported date 1900-01-01 00:00:01 with 24:00:01\n",
      "\n",
      "Processing: ./data/set_5_R6/R6_Control_1-2_Ceftrx_1300ug(ml)_1-2_11-loka-2023 14-49-16.xlsx\n",
      "Plate 1\n",
      "Replaced imported date 1900-01-01 00:00:02 with 24:00:02\n",
      "Plate 2\n",
      "Replaced imported date 1900-01-01 00:00:02 with 24:00:02\n",
      "Plate 3\n",
      "Replaced imported date 1900-01-01 00:00:02 with 24:00:02\n",
      "Plate 4\n",
      "Replaced imported date 1900-01-01 00:00:02 with 24:00:02\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "process_data(files)  # This will create a folder \"statistics\" in the working directory and write the results there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890e6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
